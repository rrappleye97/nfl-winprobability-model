<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 2 Methodology | Modeling Win Probability in NFL Games</title>
  <meta name="description" content="Chapter 2 Methodology | Modeling Win Probability in NFL Games">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 2 Methodology | Modeling Win Probability in NFL Games" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Methodology | Modeling Win Probability in NFL Games" />
  
  
  

<meta name="author" content="Robert Rappleye">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="1-data.html">
<link rel="next" href="3-results.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"></a></li>
<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="literature-review.html"><a href="literature-review.html"><i class="fa fa-check"></i>Literature Review</a></li>
<li class="chapter" data-level="1" data-path="1-data.html"><a href="1-data.html"><i class="fa fa-check"></i><b>1</b> Data</a></li>
<li class="chapter" data-level="2" data-path="2-methodology.html"><a href="2-methodology.html"><i class="fa fa-check"></i><b>2</b> Methodology</a><ul>
<li class="chapter" data-level="2.1" data-path="2-methodology.html"><a href="2-methodology.html#modeling-win-probability-on-first-and-ten"><i class="fa fa-check"></i><b>2.1</b> Modeling Win Probability on First and Ten</a></li>
<li class="chapter" data-level="2.2" data-path="2-methodology.html"><a href="2-methodology.html#modeling-win-probability-in-other-scenarios"><i class="fa fa-check"></i><b>2.2</b> Modeling Win Probability in Other Scenarios</a></li>
<li class="chapter" data-level="2.3" data-path="2-methodology.html"><a href="2-methodology.html#reasoning-behind-modeling-methodology"><i class="fa fa-check"></i><b>2.3</b> Reasoning Behind Modeling Methodology</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-results.html"><a href="3-results.html"><i class="fa fa-check"></i><b>3</b> Results</a></li>
<li class="chapter" data-level="4" data-path="4-applications.html"><a href="4-applications.html"><i class="fa fa-check"></i><b>4</b> Applications</a></li>
<li class="chapter" data-level="5" data-path="5-discussion.html"><a href="5-discussion.html"><i class="fa fa-check"></i><b>5</b> Discussion</a><ul>
<li class="chapter" data-level="5.1" data-path="5-discussion.html"><a href="5-discussion.html#conclusion"><i class="fa fa-check"></i><b>5.1</b> Conclusion</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="A-appendix.html"><a href="A-appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a><ul>
<li class="chapter" data-level="A.1" data-path="A-appendix.html"><a href="A-appendix.html#qb-model"><i class="fa fa-check"></i><b>A.1</b> QB Model</a></li>
<li class="chapter" data-level="A.2" data-path="A-appendix.html"><a href="A-appendix.html#two-point-chart"><i class="fa fa-check"></i><b>A.2</b> Two Point Chart</a></li>
<li class="chapter" data-level="A.3" data-path="A-appendix.html"><a href="A-appendix.html#clock-stop-gbm-to-predict-p_stopped"><i class="fa fa-check"></i><b>A.3</b> Clock Stop GBM to Predict <span class="math inline">\(p_{stopped}\)</span></a></li>
<li class="chapter" data-level="A.4" data-path="A-appendix.html"><a href="A-appendix.html#downs-outcome-formulas"><i class="fa fa-check"></i><b>A.4</b> Downs Outcome Formulas</a></li>
<li class="chapter" data-level="A.5" data-path="A-appendix.html"><a href="A-appendix.html#gbm-for-p_penaltyreplay"><i class="fa fa-check"></i><b>A.5</b> GBM for <span class="math inline">\(P_{penaltyReplay}\)</span></a></li>
<li class="chapter" data-level="A.6" data-path="A-appendix.html"><a href="A-appendix.html#gbms-for-p_score"><i class="fa fa-check"></i><b>A.6</b> GBMs for <span class="math inline">\(P_{score}\)</span></a></li>
<li class="chapter" data-level="A.7" data-path="A-appendix.html"><a href="A-appendix.html#linear-models-for-delta-field-position-outcome_g"><i class="fa fa-check"></i><b>A.7</b> Linear Models for <span class="math inline">\(\Delta field position | outcome_{g}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modeling Win Probability in NFL Games</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="methodology" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Methodology</h1>
<p>Instead of predicting win probability from any game state with one full-stop model, we predict win probability only from kickoff game states<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>. When the game state is not a kickoff, a series of models first specifies probability distributions for the more granular events that eventually lead to a kickoff and samples are taken from these probability distributions to create a distribution of the possible future game states at the next kickoff. Win probability is then taken to be the mean of the win probability of the distribution of sampled future game states. To implement this a given play is sorted into one of four possible game states: kickoff, extra point, first and ten, and all other game states.<br />
## Modeling Win Probability on Kickoffs and Point After Attempts</p>
<p><strong>Model when more than ten minutes remain:</strong><br />
On kickoffs a win probability is modeled using a variation of the trick PFR uses to implement a normal distribution when deriving win probability. For a given game state <span class="math inline">\(i\)</span> we have:</p>
<p><span class="math inline">\(\Delta score_i \sim \mathcal{N}(\hat{\mu}_i,\hat{\sigma}^{2}_i)\)</span> where</p>
<p><span class="math inline">\(\hat{\mu}_i = \beta_{int} + \beta_\rho\rho_i + \beta_{pos_o}{pos_o}_i + \beta_{de\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{s_{curr}}s_{curr_i}\:+\)</span><br />
<span class="math inline">\(\beta_kk_i + \beta_{kpos_o}k_ipos_{o_i} + \beta_{k{de\hspace{-0.1em}f_o}}k_i{de\hspace{-0.1em}f_{o_i}} + \beta_{s_{curr}pos_o}s_{curr_i}pos_{o_i} + \beta_{s_{curr}{de\hspace{-0.1em}f_o}}s_{curr_i}{de\hspace{-0.1em}f_{o_i}}\)</span></p>
<p>and</p>
<p><span class="math inline">\(\hat{\sigma}_i = \beta_{int} + \beta_{pos_o}{pos_o}_i + \beta_{de\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{pos_d}{pos_d}_i + \beta_{de\hspace{-0.1em}f_d}{de\hspace{-0.1em}f_d}_i + \beta_{s_{curr}}s_{curr_i} + \beta_{s_{curr_{abs}}}\mid\hspace{-0.2em}{s_{curr_i}}\hspace{-0.2em}\mid + \beta_tt_i \: +\)</span><br />
<span class="math inline">\(\beta_{ts}\sqrt{t_i} + \beta_{pos_{qb}}{pos_{qb}}_i + \beta_{de\hspace{-0.1em}f_{qb}}{de\hspace{-0.1em}f_{qb}}_i\)</span> + <span class="math inline">\(\beta_{pos_{qb}s}{pos_{qb}}_is_i + \beta_{de\hspace{-0.1em}f_{qb}s}{de\hspace{-0.1em}f_{qb}}_is_i\)</span></p>
<p>Where we define:<br />
<span class="math inline">\(int =\)</span> Intercept,<br />
<span class="math inline">\(\rho =\)</span> = Scaled point spread<br />
<span class="math inline">\(s_{curr} =\)</span> Current score differential<br />
<span class="math inline">\(s_{curr_{abs}} =\)</span> Absolute value of the current score differential<br />
<span class="math inline">\(k =\)</span> Team that receives the second half kickoff<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a><br />
<span class="math inline">\(t =\)</span> Time remaining in seconds<br />
<span class="math inline">\(pos_o =\)</span> Offensive DVOA for the team possessing the football<br />
<span class="math inline">\(pos_d =\)</span> Defensive DVOA for the team possessing the football<br />
<span class="math inline">\(de\hspace{-0.1em}f_o =\)</span> Offensive DVOA for the team on defense<br />
<span class="math inline">\(de\hspace{-0.1em}f_d =\)</span> Defensive DVOA for the team on defense<br />
<span class="math inline">\(pos_{qb} =\)</span> Projected PFF grade for the quarterback of the team with the ball<br />
<span class="math inline">\(de\hspace{-0.1em}f_{qb} =\)</span> Projected PFF grade for the quarterback of the team on defense</p>
<p>By making the observation that the final score differential is simply <span class="math inline">\(s_{curr} + \Delta score\)</span> we find:</p>
<center>
<p><span class="math inline">\(s_{final_i} \sim \mathcal{N}(\hat{\mu}_i + s_{curr_i},\,\hat{\sigma}_i^{2})\)</span> and therefore:
<span class="math inline">\(WinProb_i = P(s_{final_i} &gt; 0) = CDF^{-1}(\frac{\hat{\mu}_i + s_{curr_i}}{\hat{\sigma}^{2}_i})\)</span></p>
</center>
<p>Where we define:<br />
<span class="math inline">\(s_{final} =\)</span> Final score differential</p>
<p>The predictors for <span class="math inline">\(\mu\)</span> were chosen by performing cross validation in which the most recent season in the training set, 2016, was left out and used as a test set<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>. Horowitz, Ventura, and Yurko (2018) used a similar method and called it “leave-one-season-out-cross-validation (LOSO CV)”, a term I will modify to leave-most-recent-season-out-cross-validation and brand LMRSO CV. Brier score and log-loss were the primary estimates used to evaluate model performance. The simple linear model used was also tested against a mixed linear model that treated <span class="math inline">\(k\)</span>—receiving the second half kickoff—as a random effect and utilized an additional intercept as well as random slopes for <span class="math inline">\(pos_o\)</span> and <span class="math inline">\(de\hspace{-0.1em}f_o\)</span>, but it performed no better than the simple linear model.</p>
<p>Predictors for <span class="math inline">\(\sigma\)</span> were also chosen using LMRSO CV. The linear model used for <span class="math inline">\(\sigma\)</span> was also tested against GAMs that were fit with Gamma and Log-Normal distributions using the “gamlss” package developed by Rigby and Stasinopoulos (2005). The “gamlss” package was also used to fit a GAM with an InverseGamma distribution to model <span class="math inline">\(\sigma^{2}\)</span>, but the linear model performed the best by mean-squared error when using LMRSO CV<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>. This was surprising because the distributions specified when fitting the GAMs seemed more appropriate given the distribution of <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(\sigma^{2}\)</span>. Ultimately, however, it made the most sense to use the model with the best estimate of <span class="math inline">\(\sigma\)</span>, because only a point estimate of <span class="math inline">\(\sigma\)</span> is taken as a parameter of the normal distribution.</p>
<p>A Generalized Linear Mixed Model (GLMM) fit using the “lme4” package and a Generalized Boosted Model (GBM) fitted using Greg Ridgeway’s “gbm” package, used to extend Jerome Friedman’s Gradient Boosted Machine (2001 &amp; 2002). The above model outperforms both the GLMM and the GBM.</p>
<p><strong>Model when ten or fewer minutes remain</strong><br />
The assumption that <span class="math inline">\(\Delta score\)</span> is normally distributed begins to break down some time around the ten minute mark of the fourth quarter. Since it is no longer valid to model <span class="math inline">\(\Delta score\)</span> with a normal distribution, win probability is instead modeled using a Gradient Boosted Model (GBM) fit the following terms using the “gbm” package.</p>
<table>
<caption><span id="tab:win-prob-vars">Table 2.1: </span>Variables Used in the 4th Quarter Win Probability GBM</caption>
<thead>
<tr class="header">
<th align="left">Variables</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Scaled Point Spread</td>
</tr>
<tr class="even">
<td align="left">Current Score Differential</td>
</tr>
<tr class="odd">
<td align="left">Square Root of Adjusted Time Left in the Half</td>
</tr>
<tr class="even">
<td align="left">Offensive DVOA for the Offensive Team</td>
</tr>
<tr class="odd">
<td align="left">Offensive DVOA for the Defensive Team</td>
</tr>
<tr class="even">
<td align="left">Defensive DVOA for the Offensive Team</td>
</tr>
<tr class="odd">
<td align="left">Defensive DVOA for the Defensive Team</td>
</tr>
<tr class="even">
<td align="left">Projected QB grade for the Offensive Team</td>
</tr>
<tr class="odd">
<td align="left">Projected QB grade for the Offensive Team</td>
</tr>
<tr class="even">
<td align="left">Timeouts left for the Offense</td>
</tr>
<tr class="odd">
<td align="left">Timeouts left for the Defense</td>
</tr>
</tbody>
</table>
<p>Both a Random Forest and the GBM above were considered because of their penchant for fitting data that features predictors with ambiguous interactions, but the GBM was chosen because it performed better in LMRSO CV. Friedman’s Gradient Boosted Machine algorithm (2001 &amp; 2002), implemented in the “gbm” package, works by additively growing a forest of <span class="math inline">\(n\)</span> decision trees where each tree has a maximum depth <span class="math inline">\(d\)</span>.Trees are added to the forest using gradient descent—each tree must reduce the residual loss as defined by Friedman’s <span class="math inline">\(K\)</span>-class loss function (2001):</p>
<center>
<p><span class="math inline">\(-\sum_{k=1}^Ky_klog(p_k(x))\)</span></p>
</center>
<p>A shrinkage parameter <span class="math inline">\(l\)</span> exists to reduce the learning rate of trees. Lower values generally protect against overfitting but often require more trees to maximize predictive power. The GBM fit above uses parameters <span class="math inline">\(n = 5000\)</span>, <span class="math inline">\(d = 2\)</span>, and <span class="math inline">\(l = 0.02\)</span>.</p>
<p><strong>Overtime model</strong><br />
A GBM fit with the same variables as above but trained only on overtime data is used to determine win probability in overtime situations. This GBM has parameters <span class="math inline">\(n = 1000\)</span>, <span class="math inline">\(d = 2\)</span>, and <span class="math inline">\(l = 0.02\)</span>.</p>
<p><strong>Extra Points</strong><br />
For extra points the process only involves the additional step of sampling <span class="math inline">\(n\)</span> outcomes for the extra point or two point conversion try<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> and passing each resulting game state <span class="math inline">\(i^*_1, \: i^*_2, \:..., \: i^*_n \sim I^*\)</span> to the model that predicts win probability to find:</p>
<p><span class="math inline">\(WinProb_i = \frac{1}{n} \sum_{i^*}^{I^*}WinProb_{i^*}\)</span>, where <span class="math inline">\(WinProb_i^*\)</span> =</p>
<p><span class="math inline">\(CDF^{-1}(\frac{\hat{\mu}_{i^*} + s_{curr_{i^*}}}{\hat{\sigma}^{2}_{i^*}})\)</span> if <span class="math inline">\(t_{i^*} &gt; 600\)</span>,<br />
<span class="math inline">\(GBM_{4th}(i^*)\)</span> if <span class="math inline">\(0 &lt;t_{i^*} \leq 600\)</span>, and<br />
<span class="math inline">\(GBM_{ot}(i^*)\)</span> if <span class="math inline">\(t_{i^*} &lt; 0\)</span></p>
<div id="modeling-win-probability-on-first-and-ten" class="section level2">
<h2><span class="header-section-number">2.1</span> Modeling Win Probability on First and Ten</h2>
<p>When the game state features a first and ten we must take <span class="math inline">\(n\)</span> samples of the pair (next scoring event, time elapsed) where, just as in Horowitz, Ventura, and Yurko (2018) the seven possible outcomes for the next scoring event include a touchdown, field goal, or safety for either team and no scoring events before the end of the half. As is done by Horowitz, Ventura and Yurko (2018), the next scoring event is modeled by a multinomial logistic regression, though this work uses the Brian Ripley’s “nnet” package to implement a multinomial logistic regression instead of comparing a set of binary logistic regressions with a chosen baseline event. Modeling end of half, end of game, and overtime situations separately gave the most robust performance by LMRSO CV. The formulas for some of the linear models are the same, but each model was trained only on data within the time window where it would be applied. A multinomial GBM model was also considered. For a given initial game state <span class="math inline">\(i\)</span> we find the log odds for each possible outcome <span class="math inline">\(x\)</span> of being the next scoring event <span class="math inline">\(\delta_x\)</span> as compared to the outcome the algorithm chooses as the baseline<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a>:</p>
<p><span class="math inline">\(\delta_{ix} = \beta_{intx} + \beta_{xpos_o}{pos_o}_{i} + \beta_{xde\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{xpos_d}{pos_d}_i + \beta_{xde\hspace{-0.1em}f_d}{de\hspace{-0.1em}f_d}_i + \beta_{xpos_{st}}{pos_{st}}_i + \:\)</span><br />
<span class="math inline">\(\beta_{xde\hspace{-0.1em}f_{st}}{de\hspace{-0.1em}f_{st}}_i + \beta_{xt_{adjH}}t_{adjH_i} + \beta_{xc_{score}}c_{score_i} + \beta_{xyrd}yrd_i\)</span> if <span class="math inline">\(t_i &gt; 300 \:\: \&amp; \:\: 1800 &lt; t_i \leq 1980\)</span>,</p>
<p><span class="math inline">\(\delta_{ix} = \beta_{xint} + \beta_{xpos_o}{pos_o}_i + \beta_{xde\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{xpos_d}{pos_d}_i + \beta_{xde\hspace{-0.1em}f_d}{de\hspace{-0.1em}f_d}_i + \beta_{xpos_{st}}{pos_{st}}_i + \:\)</span><br />
<span class="math inline">\(\beta_{xde\hspace{-0.1em}f_{st}}{de\hspace{-0.1em}f_{st}}_i + \beta_{xt_{adjH}}t_{adjH_i} + \beta_{xc_{score}}c_{score_i} + \beta_{xyrd}yrd_i\)</span> if <span class="math inline">\(0 &lt; t_i \leq 300\)</span>,</p>
<p><span class="math inline">\(\delta_{ix} = \beta_{xint} + \beta_{xpos_o}{pos_o}_i + \beta_{xde\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{xpos_d}{pos_d}_i + \beta_{xde\hspace{-0.1em}f_d}{de\hspace{-0.1em}f_d}_i + \beta_{xpos_{st}}{pos_{st}}_i + \:\)</span><br />
<span class="math inline">\(\beta_{xde\hspace{-0.1em}f_{st}}{de\hspace{-0.1em}f_{st}}_i + \beta_{xt_{adjH}}t_{adjH_i} + \beta_{xyrd}yrd_i\)</span> if <span class="math inline">\(1800 &lt; t_i \leq 1980\)</span>, and</p>
<p><span class="math inline">\(\delta_{ix} = \beta_{xint} + \beta_{xpos_o}{pos_o}_i + \beta_{xde\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{xpos_d}{pos_d}_i + \beta_{xde\hspace{-0.1em}f_d}{de\hspace{-0.1em}f_d}_i + \beta_{xpos_{st}}{pos_{st}}_i + \:\)</span><br />
<span class="math inline">\(\beta_{xde\hspace{-0.1em}f_{st}}{de\hspace{-0.1em}f_{st}}_i + \beta_{xt_{adjH}}t_{adjH_i} + \beta_{xyrd}yrd_i\)</span> if <span class="math inline">\(t_i \leq 0\)</span></p>
<p>Where we define:<br />
<span class="math inline">\({pos_{st}} =\)</span> Special teams DVOA for the team with the ball<br />
<span class="math inline">\(de\hspace{-0.1em}f_{st} =\)</span> Special teams DVOA for the defensive team<br />
<span class="math inline">\(c_{score} =\)</span> Comeback score<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a><br />
<span class="math inline">\(yrd =\)</span> Number of yards needed for an offensive touchdown<br />
<span class="math inline">\(t_{adjH} =\)</span> Timeout adjusted time<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> remaining in the half</p>
<p>We don’t need to do any of the work converting the pairwise log odds into a distribution as the “nnet” package does this. We will let <span class="math inline">\(\delta_i\)</span> denote the multinomial distribution of scoring events that we will be sampling from move right and draw <span class="math inline">\(n\)</span> samples <span class="math inline">\(nextScore_{i^*_1}, \: nextScore_{i^*_2},\: ..., \: nextScore_{i^*_n} \sim \mathcal{Multinomial}(\delta_i)\)</span>. For samples where the next scoring play is a touchdown, the game state is updated to include a draw for the point after that uses the same method outlined in the “Extra Points” sub-heading of 2.1.</p>
<p>Sampling the time elapsed until the next scoring event is a bit trickier<a href="#fn18" class="footnote-ref" id="fnref18"><sup>18</sup></a>. First, a linear model<a href="#fn19" class="footnote-ref" id="fnref19"><sup>19</sup></a> predicts the number of plays, <span class="math inline">\(plays_{i^*}\)</span> for each sample <span class="math inline">\(i^*\)</span> that take place from the initial game state <span class="math inline">\(i\)</span> until kickoff for each first and ten game state:</p>
<p><span class="math inline">\(\hat{plays}_{i^*} = \beta_{int} + \beta_{pos_o}{pos_o}_i + \beta_{de\hspace{-0.1em}f_o}{de\hspace{-0.1em}f_o}_i + \beta_{pos_d}{pos_d}_i + \beta_{de\hspace{-0.1em}f_d}{de\hspace{-0.1em}f_d}_i + \beta_{yrd}\sqrt{yrd_i} + \beta_{c_{score}}c_{score_i} + \:\)</span>
<span class="math inline">\(\beta_{t_{adjH}}\sqrt{t_{adjH_i}} + \beta_{nextScore}nextScore_{i^*} + \beta_{c_{score}yrd}c_{score_i}\sqrt{yrd_i}\)</span></p>
<p>The distributions of the number of plays until the next scoring plays seems to more closely follow a Log-Normal distribution than a Normal distribution:</p>
<p><img src="thesis_files/figure-html/test-log-norm-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>To allow for more accurate sampling of the number of plays from the current game state to the next scoring play the “fitdistrplus” package by Marie-Laure Delignette-Muller is used to choose the parameters of a Log-Normal distribution that fit the data best. <span class="math inline">\(\sigma^{2}_{plays}\)</span> is set to the variance parameter of the chosen Log-Normal and we sample:</p>
<center>
<p><span class="math inline">\(log(plays_{i^*}) \sim \mathcal{N}(log(\hat{plays}_{i^*}),\sigma_{plays}^{2})\)</span> so<br />
<span class="math inline">\(plays_{i^*} = e^{log(plays_{i^*})}\)</span></p>
</center>
<p>To transform each sampled number of plays to time space we split the plays into plays that stopped the clock and plays where the clock continued to run.</p>
<center>
<p><span class="math inline">\(nStopped_{i^*} \sim \mathcal{Binom}(plays_{i^*}, p_{stopped_{i^*}})\)</span> and<br />
<span class="math inline">\(nRunning_{i^*} = plays_{i^*} - nStopped_{i^*}\)</span></p>
</center>
<p>Where <span class="math inline">\(p_{stopped_{i^*}}\)</span> is derived from a GBM detailed in the appendix. Draws that result in fewer than one clock stop are rejected because every scoring play stops the clock.</p>
<p>We next find the total time elapsed. We start by letting<br />
<span class="math inline">\(K = nStopped_{i^*}\)</span>,<br />
<span class="math inline">\(J = nRunning_{i^*}\)</span>,<br />
<span class="math inline">\(S =\)</span> time elapsed for a play after which the clock stops<br />
<span class="math inline">\(R =\)</span> time elapsed for a play after which the clock runs</p>
<p><span class="math inline">\(S_{i^*_{1}}, \: S_{i^*_{2}}, \: ... , \: S_{i^*_{K}} \sim \mathcal{N}(\hat{S_i},\sigma_{S}^{2})\)</span> where
<span class="math inline">\(\hat{S_i} = \beta_{int} + \beta_{down}down_i + \beta_{c_{score}}c_{score_i} + \beta_{ydstogo}ydstogo_i + \beta_{c_{score}down}c_{score_i}down_i\)</span></p>
<p>and</p>
<p><span class="math inline">\(R_{i^*_{1}}, \: R_{i^*_{2}}, \: ... , \: R_{i^*_{J}} \sim \mathcal{N}(\hat{R_i},\sigma_{R}^{2})\)</span> where
<span class="math inline">\(\hat{R_i} = \beta_{int} + \beta_{down}down_i + \beta_{c_{score}}c_{score_i} + \beta_{ydstogo}ydstogo_i + \beta_{c_{score}down}c_{score_i}down_i\)</span></p>
<p>We then find the time elapsed until the next scoring play as:<br />
<span class="math inline">\(elapsed_{i^*} = \sum_{k=1}^{K}S_k + \sum_{j=1}^{J}R_j\)</span></p>
<p>Samples from <span class="math inline">\(\mathcal{N}(\hat{S_i},\sigma_{S}^{2})\)</span> are rejected if they fall outside <span class="math inline">\([0, 15]\)</span> and samples from <span class="math inline">\({N}(\hat{R_i},\sigma_{R}^{2})\)</span> are rejected if they fall outside <span class="math inline">\([15, 50]\)</span> in order to restrict sampled play lengths to a realistic distribution. Additionally, the entire process for sampling a particular value for time elapsed until the next scoring event is repeated if the sample causes an invalid game state<a href="#fn20" class="footnote-ref" id="fnref20"><sup>20</sup></a> (i.e. the time elapsed is greater than the amount of time remaining in the half).</p>
<p>Finally, the game states <span class="math inline">\(i^*_1, \:i^*_2, \:..., \: i^*_n \sim I^*\)</span> are updated in accord with the values that have been sampled and we have:</p>
<p><span class="math inline">\(WinProb_i = \frac{1}{n} \sum_{i^*}^{I^*}(WinProb_{i^*})\)</span>, where <span class="math inline">\(WinProb_{i^*}\)</span> =</p>
<p><span class="math inline">\(CDF^{-1}(\frac{\hat{\mu}_{i^*} + s_{curr_{i^*}}}{\sigma^{2}_{i^*}})\)</span> for <span class="math inline">\(t_{i^*} &gt; 600\)</span>,<br />
<span class="math inline">\(GBM_{4th}(i^*)\)</span> for <span class="math inline">\(t_{i^*}\)</span> such that <span class="math inline">\(0 &lt; t_{i^*} \leq 600\)</span>,<br />
<span class="math inline">\(GBM_{ot}(i^*)\)</span> for <span class="math inline">\(t_{i^*} &lt; 0\)</span></p>
</div>
<div id="modeling-win-probability-in-other-scenarios" class="section level2">
<h2><span class="header-section-number">2.2</span> Modeling Win Probability in Other Scenarios</h2>
<p>When the game state does not fit any of the scenarios above<a href="#fn21" class="footnote-ref" id="fnref21"><sup>21</sup></a>, it is first advanced to the next set of downs. To do this we take m samples of the triple (outcome of the current set of downs, time elapsed until the next set of downs, current set of downs results in scoring play). We also sample the number of yards downfield the ball will move over the current set of downs for all draws where the current set of downs does not result in a scoring play.</p>
<p>Seven possible outcomes are also defined for a given set of downs: conversion, turnover on downs, end half, field goal attempt, punt, safety, and turnover. As was the case when modeling the next scoring event, end of half, end of game, and overtime game states are modeled separately from other game states. Additionally, separate models were fit for each down because the log loss was lower for each down when separate models were fitted for each during LMRSO CV. End of half, end of game and overtime game states were all modeled with separate GBMs fit using the “gbm” package while all other game states were modeled with a multinomial logistic regression fit with the “nnet” package. The model formulas are listed in the appendix. The models all utilize down, yards to go, DVOA ratings, quarterback grades and a version of yard line that treats each 10 yard increment of the field as a separate group to help the model make better decisions about the likelihood of field goal attempts, punts, and fourth down conversion attempts.</p>
<p><img src="thesis_files/figure-html/fg-by-yardline-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>After we have created a distribution <span class="math inline">\(\delta_i\)</span> of potential outcomes of the set of downs associated with our inital game state <span class="math inline">\(i\)</span> and sampled <span class="math inline">\(n\)</span> outcomes <span class="math inline">\(outcome_{i^*_1}, \: outcome_{i^*_2}, \:..., \:outcome_{i^*_n} \sim \mathcal{Multinomial}(\delta_i)\)</span>, we move on to sampling from the distribution of time elapsed. We begin by sampling the number of plays until the next set of downs. This is treated as:</p>
<p><span class="math inline">\(Plays_{i^*} = downstogo_{i^*} + replaysByPenalty_{i^*}\)</span> where
<span class="math inline">\(downstogo_{i^*} = 5 - down_i\)</span> for punts, turnovers on downs, and field goal attempts and<br />
<span class="math inline">\(downstogo_{i^*} \sim \mathcal{Multinomial}(outcomeDist)\)</span> for conversions, safeties, and turnovers where<br />
<span class="math inline">\(outcomeDist =\)</span><br />
<span class="math inline">\((0.349, 0.348, 0.276, 0.027)\)</span> for conversions,<br />
<span class="math inline">\((0.363, 0.312, 0.293, 0.032)\)</span> for turnovers, and<br />
<span class="math inline">\((0.333, 0.228, 0.272, 0.167)\)</span> for safeties. Additionally,<br />
<span class="math inline">\(replaysByPenalty_{i^*} \sim \mathcal{Binom}(downstogo_{i^*}, p_{penalty_i})\)</span> where<br />
<span class="math inline">\(p_{penalty_i}\)</span> is taken from a GBM that predicts the probability of a given play being replayed due to penalty. It is listed in the appendix.</p>
<p><span class="math inline">\(downstogo_{i^*}\)</span> is set to be <span class="math inline">\(5 - down_i\)</span> when <span class="math inline">\(outcome_{i^*}\)</span> is a punt, turnover on downs or field goal attempt because those plays are assumed to happen only on fourth down. The multinomial distributions for conversions, turnovers and safeties simply refer to the probability that an outcome of the given type for a set of downs occurs on a given down. Samples from the distributions that imply the event happened on a down that has already occurred are rejected. Penalty replays refers to the number of plays until the next set of downs that will be replayed by penalty. To translate a sampled number of plays into time space we use the same equations and process that was detailed in section 2.2.</p>
<p>We next sample whether a given set of downs will result in a scoring play<a href="#fn22" class="footnote-ref" id="fnref22"><sup>22</sup></a>.</p>
<p><span class="math inline">\(score_{i^*} \sim \mathcal{Multinomial}(p_{fg_i}, p_{defTD_i}, p_{noScore_i})\)</span> if <span class="math inline">\(outcome_{i^*} =\)</span> fg attempt
<span class="math inline">\(score_{i^*} \sim \mathcal{Binomial}(p_{score_i} \: | \:outcome_{i^*})\)</span> else</p>
<p><span class="math inline">\(p_{score_i} | \:outcome_{i^*}\)</span> is predicted by a GBM for sampled outcomes that are able to result in scores—conversions, field goals, punts and turnovers<a href="#fn23" class="footnote-ref" id="fnref23"><sup>23</sup></a>. Each GBM was fit using every set of downs that ended with the given outcome, and is listed in the appendix. For samples where score = 1 and the score is a touchdown, the game state is updated to include a draw for the point after that uses the same method outlined in the extra points sub-heading of 2.1. For these samples, as well as any samples where the <span class="math inline">\(outcome_{i^*}\)</span> is the end of the half, we find that for each updated game_state <span class="math inline">\(i^*\)</span> the win probability is calculated in the same manner as it was in 2.2:</p>
<p><span class="math inline">\(WinProb_{i^*}\)</span> is:<br />
<span class="math inline">\(CDF^{-1}(\frac{\hat{\mu}_{i^*} + s_{curr_{i^*}}}{\hat{\sigma}^{2}_{i^*}})\)</span> for <span class="math inline">\(t_{i^*} &gt; 600\)</span>,<br />
<span class="math inline">\(GBM_{4th}(i^*)\)</span> for <span class="math inline">\(t_{i^*}\)</span> such that <span class="math inline">\(0 &lt; t_{i^*} \leq 600\)</span>,<br />
<span class="math inline">\(GBM_{ot}(i^*)\)</span> for <span class="math inline">\(t_{i^*} &lt; 0\)</span></p>
<p>For samples where score = 0 we must also sample a value for the number of yards downfield the ball will move over the current set of downs before calculating win probability. For each outcome other than conversions and field goal attempts<a href="#fn24" class="footnote-ref" id="fnref24"><sup>24</sup></a>, two linear models are defined—one for downs first through third and one for fourth down—that specify a distribution for the number of yards downfield the ball will move for a given game state. Each linear model is listed in the appendix. The yards moved downfield is modeled separately for each possible outcome because doing so helped most of the linear models meet the assumption of constant residual variance and normally distributed errors<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a>, allowing for easier sampling. The same reasoning is behind separating fourth down data from other data when fitting each model—the residual variance should be lower on fourth down for each outcome type because there is no longer uncertainty about where a punt, field goal attempt, etc. will be taken from. Conversions are a special case and are split into regular conversions and conversions by penalty.</p>
<center>
<span class="math inline">\(ConversionType_{i^*} \sim \mathcal Bernoulli(p_{penaltyConv_i})\)</span> if <span class="math inline">\(outcome_{i^*} =\)</span> conversion
</center>
<p><span class="math inline">\(p_{penaltyConv_i}\)</span> is defined by a logistic regression that has been trained on all conversion plays. The model only looked at the current down, the yards to go for a first and the interaction between the two variables. Yards moved downfield for conversions by penalty are also modeled with two linear models, one for fourth down and one for any other down. For regular conversions a linear model is specified for each down to better satisfy the linear regression constraints. Field goal attempts also work differently. Field goal attempts that don’t result in a score are classified as either a regular miss or a block.</p>
<center>
<span class="math inline">\(fgBlock_{i^*} \sim \mathcal Bernoulli(p_{block})\)</span>
</center>
<p><span class="math inline">\(p_{block}\)</span> is modeled using a GBM where the only predictors are yard line<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> and down, where down likely only matters in the sense that it alerts the model as to whether the yard line might change between the current game state and any field goal try. The change in field position on regular field goal misses is modeled by a linear regression when the down is not fourth. On fourth down the ball is simply moved back 7 yards as is customary on missed field goals. Blocked field goals require the same protocol for determing change in field position as other possible outcomes. One linear model is used for downs first through third and another for fourth. For a given output <span class="math inline">\(\Delta\hat{fieldPosition}_i^*\)</span> from the model <span class="math inline">\(m\)</span> that is specified by <span class="math inline">\(outcome_{i^*}\)</span> we take a sample:</p>
<center>
<span class="math inline">\(\Delta fieldPosition_i^* \sim \mathcal N(\Delta\hat{fieldPosition}_i^*, \sigma^{2}_{\epsilon_m})\)</span>
</center>
<p>Samples drawn are rejected if they result in an invalid or illogical game state. Examples include first down conversions not by penalty where the draw would cause the game state to be short of the first down marker, a turnover on downs where the draw causes the ball to move past the first down marker, or any draw where the resulting game state features a yard line outside <span class="math inline">\([1, 99]\)</span>.</p>
<p>Once we have samples for the number of yards the ball has moved downfield we can fully update each of the game states for which a scoring outcome was not sampled. Each of these <span class="math inline">\(m \leq n\)</span> remaining game states <span class="math inline">\(i^*_1, \: i^*_2, \:..., \:i^*_m \sim I^*\)</span> will then go through the process outlined in 2.2. This will lead to the creation of <span class="math inline">\(M\)</span> new game states <span class="math inline">\(j^*_1, \: j^*_2, \:..., \:j^*_M \sim J^* \:| \: i^*\)</span>advanced from each game state <span class="math inline">\(i^*\)</span> and will result in:</p>
<p><span class="math inline">\(WinProb_{i^*} = \frac{1}{M}\sum_{j^*}^{J^*}WinProb_{j^* \: | \: i^*}\)</span>, where <span class="math inline">\(WinProb_{j^*} \: | \: i^*\)</span> is:<br />
<span class="math inline">\(CDF^{-1}(\frac{\hat{\mu}_{j*} + s_{curr_{j*}}}{\hat{\sigma}^{2}_{j*}}\:|\:i^*)\)</span> for <span class="math inline">\(t_{j*}\:|\:i^* &gt; 600\)</span>,<br />
<span class="math inline">\(GBM_{4th}(j^*\:|\:i^*)\)</span> for <span class="math inline">\(t_{j^*}\:|\:i^*\)</span> such that <span class="math inline">\(0 &lt; t_{j^*} \leq 600\)</span>,<br />
<span class="math inline">\(GBM_{ot}(j^*\:|\:i^*)\)</span> for <span class="math inline">\(t_{j^*}\:|\:i^* &lt; 0\)</span></p>
<p>The resulting <span class="math inline">\(WinProb_i\)</span> for the initial state <span class="math inline">\(i\)</span> is then computed by taking averaging the values for of win probability for each game state <span class="math inline">\({i^*}\)</span><a href="#fn27" class="footnote-ref" id="fnref27"><sup>27</sup></a>:</p>
<center>
<span class="math inline">\(WinProb_i = \frac{1}{n} \sum_{i^*}^{I^*}WinProb_{i^*}\)</span>
</center>
</div>
<div id="reasoning-behind-modeling-methodology" class="section level2">
<h2><span class="header-section-number">2.3</span> Reasoning Behind Modeling Methodology</h2>
<p>This methodology has several benefits. The first is that the impact of some game state descriptors like down, yards to go for a first down, and field position should theoretically be easier to measure on events they directly impact, like the outcome of a given set of downs, than on events they indirectly impact, like the probability of winning the game. Reducing noise around the measurement of the effects of game state descriptors like down, yards to go and yard line should improve model accuracy. Another benefit of modeling win probability like this is that it allows for a full distribution of EPA to be specified rather than a point estimate. This gives a better estimate of the variance associated with the game state which should lead to more accurate model predictions. Additionally, giving the model an estimate of the distribution of time that will elapse between the current game state and the next score gives the model an even fuller picture of the game and should help aid model accuracy, particularly towards the end of game. The modeling methodology also makes it easier to update the model piecemeal. If research comes out about the factors that influence the likelihood of converting a given set of downs, it shouldn’t be very hard to incorporate the findings into the multinomial models that are currently in place to handle predicting the outcome of a given set of downs. It’s also nice to get many of the benefits of a simulation without having to specify an exhaustive grid of conditional probabilities<a href="#fn28" class="footnote-ref" id="fnref28"><sup>28</sup></a>.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="10">
<li id="fn10"><p>Each of the models will be described in greater detail later on in the section<a href="2-methodology.html#fnref10" class="footnote-back">↩</a></p></li>
<li id="fn11"><p>1 if the team that has the ball will receive the second half kickoff, -1 if the defensive team will receive the second half kickoff, and 0 if the game is already past halftime<a href="2-methodology.html#fnref11" class="footnote-back">↩</a></p></li>
<li id="fn12"><p>The most recent season was chosen as the season to leave out because the model will always be tasked with using past results to predict future results in practice, and it seems likely that rule changes and evolving strategy could cause gradual changes in game play over time. If these changes are even somewhat smooth, it will be useful to tune models on data that will differ from the training set in a similar manner to the way the next season’s batch of data will differ from the current season’s.<a href="2-methodology.html#fnref12" class="footnote-back">↩</a></p></li>
<li id="fn13"><p>Error for <span class="math inline">\(\sigma^{2}\)</span> was determined after taking the square root<a href="2-methodology.html#fnref13" class="footnote-back">↩</a></p></li>
<li id="fn14"><p>A chart defining situations where a team is classified as going for two is listed in the appendix<a href="2-methodology.html#fnref14" class="footnote-back">↩</a></p></li>
<li id="fn15"><p>A conversion in this case<a href="2-methodology.html#fnref15" class="footnote-back">↩</a></p></li>
<li id="fn16"><p>The comeback score variable is meant to define the urgency of a comeback situation to help the models that measure time elapsed provide more accurate probability distributions when the game state is being advanced. It is also used in some of the end of game models as a feature that gives an indication of the relationship between score differential and time remaining.<a href="2-methodology.html#fnref16" class="footnote-back">↩</a></p></li>
<li id="fn17"><p>The amount of time remaining in the half + 20 secs for every timeout possessed by a team with a comeback score of four or five<a href="2-methodology.html#fnref17" class="footnote-back">↩</a></p></li>
<li id="fn18"><p>Except when the next scoring play is sample to be the end of the half in which case time elapsed is just the time remaining in the half<a href="2-methodology.html#fnref18" class="footnote-back">↩</a></p></li>
<li id="fn19"><p>It outperformed a GAM assuming a Log-Normal distribution with the same inputs by LMRSO CV<a href="2-methodology.html#fnref19" class="footnote-back">↩</a></p></li>
<li id="fn20"><p>If a sample is rejected more than 10 times it is that the game state that will result in the end of the half and was misclassified<a href="2-methodology.html#fnref20" class="footnote-back">↩</a></p></li>
<li id="fn21"><p>This will occur on any second, third, or fourth down play, as well as on first downs where there are more or less than ten yards to go<a href="2-methodology.html#fnref21" class="footnote-back">↩</a></p></li>
<li id="fn22"><p>All sets of downs where the sampled outcome is a safety are treated as scoring plays<a href="2-methodology.html#fnref22" class="footnote-back">↩</a></p></li>
<li id="fn23"><p>Scores on conversions are assumed to be offensive touchdowns and scores on punts and turnovers are assumed to be defensive touchdowns<a href="2-methodology.html#fnref23" class="footnote-back">↩</a></p></li>
<li id="fn24"><p>and end of halves where we don’t need to sample this quantity at all<a href="2-methodology.html#fnref24" class="footnote-back">↩</a></p></li>
<li id="fn25"><p>The exception to this is when the outcome of the set of downs is a conversion, but rejecting samples that were behind the first down marker alleviated this.<a href="2-methodology.html#fnref25" class="footnote-back">↩</a></p></li>
<li id="fn26"><p>Given a missed field goal, the shorter the attempt was, the more likely it was to be blocked<a href="2-methodology.html#fnref26" class="footnote-back">↩</a></p></li>
<li id="fn27"><p>This includes the game states for which <span class="math inline">\(score{i^*}\)</span> was equal to one and <span class="math inline">\(WinProb_{i^*}\)</span> was calculated earlier.<a href="2-methodology.html#fnref27" class="footnote-back">↩</a></p></li>
<li id="fn28"><p>Though this modeling protocol certainly comes with its fair share of edge cases to account for.<a href="2-methodology.html#fnref28" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="1-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="3-results.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
